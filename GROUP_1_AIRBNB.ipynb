{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/agentilt/Airbnb_EDA/blob/main/GROUP_1_AIRBNB.ipynb)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3Iv0XGGxCWu"
      },
      "source": [
        "# INSTRUCTIONS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZt2xwiZs4pE"
      },
      "source": [
        "**Perform a basic exploratory data analysis of the Inside Airbnb dataset and answer some questions**\n",
        "\n",
        "To complete the assignment, paste the answers where appropriate, and upload the full notebook at the end.\n",
        "\n",
        "\n",
        "**Submission format**: One Jupyter notebook (`Airbnb_GroupX.ipynb`).\n",
        "\n",
        "Please do *not* submit:\n",
        "* A zip file\n",
        "* A link to Google CoLab\n",
        "* A file with the wrong extension\n",
        "* A Python script\n",
        "\n",
        "\n",
        "To complete the assignment, follow the steps. The data is attached below.\n",
        "\n",
        "\n",
        "The grading criteria are, in decreasing order of importance and increasing object of subjectivity, as follows:\n",
        "\n",
        "\n",
        "* Code has no errors, the whole notebook runs from top to bottom without modifications (35 %)\n",
        "* Code gives correct answers (30 %)\n",
        "* Code avoids repetition and favours pandas methods where appropriate (loops and conditionals only if strictly necessary) (15 %)\n",
        "* Code uses meaningful, explanatory variable names (10 %)\n",
        "Code is as succinct as possible (when there are two ways of doing something, the simplest, shortest, or easier to understand is chosen) (5 %)\n",
        "  * If you discuss several ways of doing something, with its pros and cons (without just dumping the code and no explanations), that counts positively as well\n",
        "* Code is easy to read (i.e. \"similar to how the professor codes\") (5 %)\n",
        "\n",
        "\n",
        "Optionally, you can include code comments describing the intent (i.e. code comments should answer \"why is this code here?\", not \"what is this code doing?\") and supplementary markdown cells if appropriate.\n",
        "\n",
        "\n",
        "\n",
        "All the questions can be done independently of each other (after reading the data). They are not sorted in any particular order of difficulty."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NxKCKktVw6G6"
      },
      "source": [
        "#IMPORT LIBRARIES AND DATASET\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "df = pd.read_csv('listings.csv')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UM2jPNyIyhEq"
      },
      "source": [
        "# PART 1: BASIC EXPLORATORY ANALYSIS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOz4slwrx263"
      },
      "source": [
        "**Question 1**\n",
        "\n",
        "How many rows does the dataset have? (Excluding the header containing the column names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of rows: 25000\n"
          ]
        }
      ],
      "source": [
        "# Use len() function to count the number of rows in the DataFrame\n",
        "# len(df) returns the number of rows (excluding the header)\n",
        "# f\"...\" is an f-string (formatted string) - allows us to insert variables using {}\n",
        "# The variable len(df) is evaluated and inserted into the string\n",
        "print(f\"Number of rows: {len(df)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nziLToOnzGLS"
      },
      "source": [
        "**Question 2**\n",
        "\n",
        "How many columns does the dataset have? (Excluding the autogenerated numerical index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of columns: 79\n"
          ]
        }
      ],
      "source": [
        "# df.columns returns a list-like object containing all column names\n",
        "# len(df.columns) counts how many columns are in the DataFrame\n",
        "# f-string formats the output with the column count inserted\n",
        "print(f\"Number of columns: {len(df.columns)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ioAMcUe-zb8Q"
      },
      "source": [
        "**Question 3**\n",
        "\n",
        "How many unique values are there for host_id?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of unique host_id values: 10453\n"
          ]
        }
      ],
      "source": [
        "# Access the 'host_id' column using df['host_id'] \n",
        "# .nunique() counts the number of unique (distinct) values in the column\n",
        "# This tells us how many different hosts there are \n",
        "# Store the result in variable 'unique_hosts' for later use\n",
        "unique_hosts = df['host_id'].nunique()\n",
        "\n",
        "# Print the result using f-string formatting\n",
        "# {unique_hosts} inserts the value of the variable into the string\n",
        "print(f\"Number of unique host_id values: {unique_hosts}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1exhESrzeH9"
      },
      "source": [
        "**Question 4**\n",
        "\n",
        "Count how many listings are there per host (where 1 row = 1 listing). Find the host with the largest number of listings. How many listings do they have?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Host with the largest number of listings (host_id: 438136382) has 407 listings\n"
          ]
        }
      ],
      "source": [
        "# .value_counts() counts how many times each unique value appears in the column\n",
        "# Returns a Series with counts for each host_id\n",
        "listings_per_host = df['host_id'].value_counts()\n",
        "\n",
        "# .idxmax() returns the index (host_id) with the maximum count value\n",
        "# .max() returns the maximum count value itself\n",
        "# We use both in the f-string to show which host has the most listings and how many\n",
        "# Method chaining: we call .idxmax() and .max() directly on the Series\n",
        "print(f\"Host with the largest number of listings (host_id: {listings_per_host.idxmax()}) has {listings_per_host.max()} listings\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXAE8MOKzgJh"
      },
      "source": [
        "**Question 5**\n",
        "\n",
        "How many distinct hosts are superhosts?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of distinct superhosts: 2543\n"
          ]
        }
      ],
      "source": [
        "# This uses boolean indexing \n",
        "# df['host_is_superhost'] == 't' creates a boolean Series (True/False for each row)\n",
        "# df[...] filters rows where the condition is True (only superhosts)\n",
        "# ['host_id'] selects just the host_id column from filtered rows\n",
        "# .nunique() counts unique host_ids \n",
        "# Note: 't' means 'true' in this dataset (Airbnb uses 't'/'f' for boolean values)\n",
        "superhosts = df[df['host_is_superhost'] == 't']['host_id'].nunique()\n",
        "\n",
        "# Print the count of distinct superhosts\n",
        "print(f\"Number of distinct superhosts: {superhosts}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owpxqGE7zkMH"
      },
      "source": [
        "**Question 6**\n",
        "\n",
        "In the city of Madrid there are 2 administrative levels represented in the dataset: neighbourhood and district. Find the district with the largest number of listings. How many does it have?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "District with the largest number of listings: Centro with 10230 listings\n"
          ]
        }
      ],
      "source": [
        "# Count how many listings each district has\n",
        "# 'neighbourhood_group_cleansed' contains the district names\n",
        "# .value_counts() returns a Series with district names as index and counts as values\n",
        "listings_per_district = df['neighbourhood_group_cleansed'].value_counts()\n",
        "\n",
        "# Find the district with maximum listings\n",
        "# .idxmax() gets the district name (index) with highest count\n",
        "# .max() gets the actual maximum count value\n",
        "print(f\"District with the largest number of listings: {listings_per_district.idxmax()} with {listings_per_district.max()} listings\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GoxuWeWNzmvA"
      },
      "source": [
        "**Question 7**\n",
        "\n",
        "What's the average price of listings? (Error of +-1 USD is accepted)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average price: $156.69\n"
          ]
        }
      ],
      "source": [
        "# Price column is stored as text (string) with '$' and commas\n",
        "# We need to convert it to a number to calculate the average\n",
        "# Method chaining: multiple operations in sequence\n",
        "# .str.replace('$', '') removes dollar signs from all values\n",
        "# .str.replace(',', '') removes commas (thousands separators)\n",
        "# .astype(float) converts the string to a float (decimal number)\n",
        "# We create a new column 'price_numeric' to store the converted values\n",
        "df['price_numeric'] = df['price'].str.replace('$', '').str.replace(',', '').astype(float)\n",
        "\n",
        "# Calculate the mean (average) of all prices\n",
        "# .mean() is a pandas method that calculates the average of numeric values\n",
        "average_price = df['price_numeric'].mean()\n",
        "\n",
        "# Print with formatting: ${average_price:.2f}\n",
        "# :.2f means format as float with 2 decimal places\n",
        "print(f\"Average price: ${average_price:.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLGpLUsYzplL"
      },
      "source": [
        "**Question 8**\n",
        "\n",
        "How many listings have zero reviews?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of listings with zero reviews: 5147\n"
          ]
        }
      ],
      "source": [
        "# Boolean comparison: df['number_of_reviews'] == 0 creates True/False for each row\n",
        "# Parentheses () group the operation\n",
        "# .sum() on a boolean Series counts True values (True=1, False=0 when summed)\n",
        "# This counts how many rows have number_of_reviews equal to 0\n",
        "zero_reviews = (df['number_of_reviews'] == 0).sum()\n",
        "\n",
        "# Print the count of listings with zero reviews\n",
        "print(f\"Number of listings with zero reviews: {zero_reviews}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1xoaZTSzrTA"
      },
      "source": [
        "**Question 9**\n",
        "\n",
        "Fill the gap: \"Listings that are instantly bookable have an average number of reviews per month X % higher than those that are not\" (Error of +-1 % is accepted)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average reviews per month (instant bookable): 2.09\n",
            "Average reviews per month (not instant bookable): 1.50\n",
            "Percentage difference: 39.7%\n"
          ]
        }
      ],
      "source": [
        "# Filter rows where instant_bookable == 't' (true), then get reviews_per_month column, then calculate mean\n",
        "# This gives us the average reviews per month for instantly bookable listings\n",
        "instant_bookable_avg = df[df['instant_bookable'] == 't']['reviews_per_month'].mean()\n",
        "\n",
        "# Same process but for listings that are not instantly bookable \n",
        "not_instant_bookable_avg = df[df['instant_bookable'] == 'f']['reviews_per_month'].mean()\n",
        "\n",
        "# Calculate percentage difference: ((new - old) / old) * 100\n",
        "# This is the standard formula for percentage increase\n",
        "# Ternary operator: if not_instant_bookable_avg != 0 then calculate, else return 0\n",
        "# This prevents division by zero error if there are no non-instant-bookable listings\n",
        "percentage_difference = ((instant_bookable_avg - not_instant_bookable_avg) / not_instant_bookable_avg) * 100 if not_instant_bookable_avg != 0 else 0\n",
        "\n",
        "# Print all three values with appropriate formatting\n",
        "# :.2f formats to 2 decimal places, :.1f formats to 1 decimal place\n",
        "print(f\"Average reviews per month (instant bookable): {instant_bookable_avg:.2f}\")\n",
        "print(f\"Average reviews per month (not instant bookable): {not_instant_bookable_avg:.2f}\")\n",
        "print(f\"Percentage difference: {percentage_difference:.1f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pjrh9SVPzs3h"
      },
      "source": [
        "**Question 10**\n",
        "\n",
        "How many listings have missing (null) license information?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of listings with missing license information: 15812\n"
          ]
        }
      ],
      "source": [
        "# .isna() checks each value in the column and returns True if it's NaN (Not a Number/missing)\n",
        "# Returns a boolean Series (True for missing, False for present)\n",
        "# .sum() counts the True values (missing values)\n",
        "# This tells us how many listings have null/missing license information\n",
        "missing_license = df['license'].isna().sum()\n",
        "\n",
        "# Print the count of missing license values\n",
        "print(f\"Number of listings with missing license information: {missing_license}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yd9fIVMnzuNE"
      },
      "source": [
        "**Question 11**\n",
        "\n",
        "Some licenses have a very long string starting with ES, followed by 2 letters (type of listing), followed by 2 letters (category), followed by a long list of numbers and some extra characters.\n",
        "\n",
        "How many listings have a license containing the string \"ESFC\"?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of listings with license containing 'ESFC': 4790\n"
          ]
        }
      ],
      "source": [
        "# .str.contains() searches for a substring within each string value\n",
        "# 'ESFC' is the pattern we're looking for\n",
        "# na=False means: if a value is NaN (missing), return False instead of NaN\n",
        "# Returns a boolean Series (True if 'ESFC' found, False otherwise)\n",
        "# .sum() counts how many True values (how many contain 'ESFC')\n",
        "esfc_license_count = df['license'].str.contains('ESFC', na=False).sum()\n",
        "\n",
        "# Print the count of licenses containing 'ESFC'\n",
        "print(f\"Number of listings with license containing 'ESFC': {esfc_license_count}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ntdjKQklzvt4"
      },
      "source": [
        "**Question 12**\n",
        "\n",
        "How many listings have declared \"Exempt\" or \"En proceso\" in the license field?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of listings with 'Exempt' or 'En proceso' in license: 964\n"
          ]
        }
      ],
      "source": [
        "# .str.contains() with regex pattern 'Exempt|En proceso'\n",
        "# The | symbol means \"OR\" in regular expressions \n",
        "# So this searches for either \"Exempt\" OR \"En proceso\" in the license field\n",
        "# case=False means case-insensitive search (matches \"EXEMPT\", \"exempt\", \"Exempt\", etc.)\n",
        "# na=False handles missing values by returning False\n",
        "# .sum() counts how many licenses contain either string\n",
        "exempt_or_proceso = df['license'].str.contains('Exempt|En proceso', case=False, na=False).sum()\n",
        "\n",
        "# Print the count\n",
        "print(f\"Number of listings with 'Exempt' or 'En proceso' in license: {exempt_or_proceso}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GjzF1lnyzw4G"
      },
      "source": [
        "**Question 13**\n",
        "\n",
        "How many hosts *cannot* be contacted by email?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of hosts that cannot be contacted by email: 1344\n"
          ]
        }
      ],
      "source": [
        "# We want to find hosts who CANNOT be contacted by email\n",
        "# ~ is the NOT operator in pandas \n",
        "# df['host_verifications'].str.contains('email', na=False) finds rows WITH email\n",
        "# ~ inverts it to find rows WITHOUT email\n",
        "# [~...] filters to only rows where email is NOT found\n",
        "# ['host_id'] selects the host_id column from filtered rows\n",
        "# .nunique() counts unique host_ids (distinct hosts without email)\n",
        "hosts_without_email = df[~df['host_verifications'].str.contains('email', na=False)]['host_id'].nunique()\n",
        "\n",
        "# Print the count of hosts without email contact\n",
        "print(f\"Number of hosts that cannot be contacted by email: {hosts_without_email}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mahIR7yYzyGW"
      },
      "source": [
        "**Question 14**\n",
        "\n",
        "What's the maximum number of amenities found in any listing?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Maximum number of amenities in any listing: 95\n"
          ]
        }
      ],
      "source": [
        "# Amenities are stored as a JSON-like string\n",
        "# To count amenities, we count commas and add 1 (since n items = n-1 commas)\n",
        "# .fillna('[]') replaces missing values with empty array string '[]' before processing\n",
        "# This prevents errors when working with NaN values\n",
        "# .str.count(',') counts commas in each string\n",
        "# + 1 because if there are 2 commas, there are 3 items\n",
        "df['amenities_count'] = df['amenities'].fillna('[]').str.count(',') + 1\n",
        "\n",
        "# Fix empty arrays: if amenities is '[]' (empty), set count to 0\n",
        "# df.loc[...] selects specific rows and columns for assignment\n",
        "# Condition: df['amenities'].fillna('[]').str.strip() == '[]' finds empty arrays\n",
        "# .str.strip() removes whitespace, == '[]' checks if it's an empty array\n",
        "# 'amenities_count' is the column we're updating\n",
        "# = 0 sets the count to 0 for empty arrays\n",
        "df.loc[df['amenities'].fillna('[]').str.strip() == '[]', 'amenities_count'] = 0\n",
        "\n",
        "# Find the maximum value in the amenities_count column\n",
        "# .max() returns the highest count value\n",
        "max_amenities = df['amenities_count'].max()\n",
        "\n",
        "# Print the maximum number of amenities found\n",
        "print(f\"Maximum number of amenities in any listing: {max_amenities}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4iQAF6LzzJ8"
      },
      "source": [
        "**Question 15**\n",
        "\n",
        "Which year has the record for number of hosts registered?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Year with the record for number of hosts registered: 2016.0 (1287 hosts)\n"
          ]
        }
      ],
      "source": [
        "# Extract year from host_since column \n",
        "# pd.to_datetime() converts string dates to datetime objects (Python date format)\n",
        "# .dt.year extracts just the year part (2010, 2011, etc.) from each date\n",
        "# Creates a new column 'host_since_year' with just the year\n",
        "df['host_since_year'] = pd.to_datetime(df['host_since']).dt.year\n",
        "\n",
        "# Group data by year and count unique hosts registered in each year\n",
        "# .groupby('host_since_year') groups rows by year\n",
        "# ['host_id'] selects the host_id column from each group\n",
        "# .nunique() counts unique host_ids in each year (distinct hosts registered)\n",
        "# Result: a Series with years as index and host counts as values\n",
        "hosts_per_year = df.groupby('host_since_year')['host_id'].nunique()\n",
        "\n",
        "# Find which year has the maximum number of hosts\n",
        "# .idxmax() returns the index (year) with the maximum value\n",
        "year_with_max_hosts = hosts_per_year.idxmax()\n",
        "\n",
        "# Get the actual maximum count value\n",
        "max_hosts_count = hosts_per_year.max()\n",
        "\n",
        "# Print the year and count\n",
        "print(f\"Year with the record for number of hosts registered: {year_with_max_hosts} ({max_hosts_count} hosts)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ii6Or70Hyp1e"
      },
      "source": [
        "# PART 2: OPEN ENDED ANALYSIS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FaG19c1xyy4t"
      },
      "source": [
        "**Question 16**\n",
        "\n",
        "Examine the \"license\" field a bit more closely. There are different structures present, apart from the one described above. Try to identify them and count how many listings have each type of license."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Other license patterns found:\n",
            "License type counts:\n",
            "ESFC pattern (ES + 2 letters + 2 letters + numbers)     6221\n",
            "Exempt                                                   661\n",
            "En proceso                                               303\n",
            "Missing/Null                                           15812\n",
            "Other: 350202309690                                       27\n",
            "Other: VT REGISTRADA                                      23\n",
            "Other: EXENTO - Alquiler de Temporada según la LAU        21\n",
            "Other: VT                                                 21\n",
            "Other: AM-336                                             20\n",
            "Other: 106/2006/1387                                      18\n",
            "Other: VT-3483                                            16\n",
            "Other: VT-14732                                           12\n",
            "Other: VT-5980                                            10\n",
            "Other: 350/2022/13778                                     10\n"
          ]
        }
      ],
      "source": [
        "# Explore the license field to identify different license structures\n",
        "# Check for ESFC pattern using regular expression \n",
        "# r'^ES[A-Z]{2}[A-Z]{2}' means: starts with ES, then 2 uppercase letters, then 2 uppercase letters\n",
        "# ^ means \"starts with\", [A-Z]{2} means exactly 2 uppercase letters\n",
        "# regex=True enables regex pattern matching\n",
        "# Returns boolean Series (True if pattern matches)\n",
        "esfc_pattern = df['license'].str.contains(r'^ES[A-Z]{2}[A-Z]{2}', na=False, regex=True)\n",
        "\n",
        "# Check for \"Exempt\" text (case-insensitive)\n",
        "exempt = df['license'].str.contains('Exempt', case=False, na=False)\n",
        "\n",
        "# Check for \"En proceso\" text (case-insensitive)\n",
        "en_proceso = df['license'].str.contains('En proceso', case=False, na=False)\n",
        "\n",
        "# Build a pandas Series to store license type counts\n",
        "# pd.Series() creates a Series \n",
        "# Dictionary format: {'label': value}\n",
        "# .sum() on boolean Series counts True values (how many match each pattern)\n",
        "license_types = pd.Series({\n",
        "    'ESFC pattern (ES + 2 letters + 2 letters + numbers)': esfc_pattern.sum(),\n",
        "    'Exempt': exempt.sum(),\n",
        "    'En proceso': en_proceso.sum(),\n",
        "    'Missing/Null': df['license'].isna().sum()\n",
        "})\n",
        "\n",
        "# Find licenses that don't match any of the standard patterns\n",
        "# ~ negates each boolean Series (NOT esfc, NOT exempt, NOT en_proceso)\n",
        "# & combines conditions with AND (all must be True)\n",
        "# df['license'].notna() ensures we only look at non-missing values\n",
        "# Result: boolean mask identifying non-standard licenses\n",
        "non_standard_mask = ~esfc_pattern & ~exempt & ~en_proceso & df['license'].notna()\n",
        "\n",
        "# Check if there are any non-standard licenses\n",
        "# .any() returns True if any value in the Series is True\n",
        "if non_standard_mask.any():\n",
        "    # Filter to non-standard licenses and count occurrences\n",
        "    # df.loc[mask, 'license'] selects license column where mask is True\n",
        "    # .value_counts() counts how many times each unique license appears\n",
        "    # .head(10) gets only the top 10 most common non-standard licenses\n",
        "    other_licenses = df.loc[non_standard_mask, 'license'].value_counts().head(10)\n",
        "    \n",
        "    # Modify the index (license names) to add \"Other: \" prefix\n",
        "    # .index accesses the index (row labels) of the Series\n",
        "    # .str[:50] truncates long license names to first 50 characters\n",
        "    other_licenses.index = 'Other: ' + other_licenses.index.str[:50]\n",
        "    \n",
        "    # Combine the standard license types with non-standard ones\n",
        "    # pd.concat() concatenates/combines multiple Series into one\n",
        "    # [license_types, other_licenses] is a list of Series to combine\n",
        "    license_types = pd.concat([license_types, other_licenses])\n",
        "    print(\"Other license patterns found:\")\n",
        "\n",
        "# Display all license type counts\n",
        "# .to_string() formats the Series as a readable string table\n",
        "print(\"License type counts:\")\n",
        "print(license_types.to_string())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9UqOFB7y2Ql"
      },
      "source": [
        "**Question 17**\n",
        "\n",
        "The \"host_location\" information is somewhat structured. Sometimes it contains (city, country), sometimes it doesn't. Explore how many different countries are present, trying to pay attention to typos, special values (like state names), and which are the most prevalent ones, other than Spain."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top countries (excluding Spain):\n",
            "extracted_country\n",
            "United Kingdom          115\n",
            "France                   58\n",
            "Germany                  44\n",
            "Mexico                   43\n",
            "Argentina                40\n",
            "Colombia                 38\n",
            "FL                       24\n",
            "Italy                    23\n",
            "CA                       23\n",
            "Brazil                   23\n",
            "NY                       22\n",
            "Switzerland              18\n",
            "Netherlands              14\n",
            "Peru                     13\n",
            "Portugal                 12\n",
            "United Arab Emirates     10\n",
            "Venezuela                10\n",
            "Australia                 8\n",
            "Panama                    8\n",
            "United States             7\n",
            "\n",
            "Total unique country values (including variations): 77\n",
            "Total unique host_location values: 440\n"
          ]
        }
      ],
      "source": [
        "# Extract country from host_location field\n",
        "# Format is usually \"City, Country\" (e.g., \"Madrid, Spain\")\n",
        "# Method chaining: multiple string operations in sequence\n",
        "# .fillna('') replaces missing values with empty string (prevents errors)\n",
        "# .str.split(',') splits each string at commas, returns list ['City', ' Country']\n",
        "# .str[-1] gets the last element of each list (the country part)\n",
        "# .str.strip() removes leading/trailing whitespace\n",
        "# Creates new column 'extracted_country' with just country names\n",
        "df['extracted_country'] = df['host_location'].fillna('').str.split(',').str[-1].str.strip()\n",
        "\n",
        "# Count how many hosts are from each country\n",
        "# .value_counts() counts occurrences of each unique country\n",
        "country_counts = df['extracted_country'].value_counts()\n",
        "\n",
        "# Filter to show top countries excluding Spain and empty strings\n",
        "# country_counts.index accesses the country names (index of the Series)\n",
        "# != 'Spain' excludes Spain, != '' excludes empty strings\n",
        "# & combines both conditions (both must be True)\n",
        "# .head(20) gets the top 20 countries by count\n",
        "top_countries = country_counts[(country_counts.index != 'Spain') & (country_counts.index != '')].head(20)\n",
        "\n",
        "# Display the top countries\n",
        "print(\"Top countries (excluding Spain):\")\n",
        "# .to_string() formats as a readable table\n",
        "print(top_countries.to_string())\n",
        "\n",
        "# Analyze data quality: check for typos and variations\n",
        "# .nunique() counts unique values (helps identify if there are typos/variations)\n",
        "# \\n creates a new line in the output\n",
        "print(f\"\\nTotal unique country values (including variations): {df['extracted_country'].nunique()}\")\n",
        "print(f\"Total unique host_location values: {df['host_location'].nunique()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74L6aOKky39H"
      },
      "source": [
        "**Question 18**\n",
        "\n",
        "A few listings seem to be extremely expensive. Devise a method of extracting price outliers, and inspect those listings. Which ones have been most reviewed? Do they have more amenities than average? Highlight anything else that's interesting about them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of price outliers (above $305.00): 1183\n",
            "\n",
            "Outlier price statistics:\n",
            "  Min price: $306.00\n",
            "  Max price: $25654.00\n",
            "  Mean price: $788.97\n",
            "\n",
            "Top 5 most reviewed outliers:\n",
            "            id                                                name  price_numeric  number_of_reviews  amenities_count host_is_superhost  review_scores_rating\n",
            "363    3146468                   Cozy room in the center of Madrid          627.0                603               14                 f                  4.82\n",
            "1292  11990713  1-12.Las Cortes.Sol.Madrid Center.120m2 Bright.A.C          430.0                574               36                 t                  4.84\n",
            "829    7571127  Calle Mayor, central, bright & spacious, AC, WiFi.          536.0                568               37                 t                  4.67\n",
            "695    6542642      The Best Location-2 Steps From Gran Vía! (v10)          312.0                546               48                 f                  4.88\n",
            "4395  30761904  Stunning Centrally Located Apartment by Eric Vökel          339.0                536               52                 t                  4.81\n",
            "\n",
            "Average amenities:\n",
            "  Outliers: 29.99\n",
            "  All listings: 25.69\n",
            "  Difference: 4.30\n",
            "\n",
            "Other insights about outliers:\n",
            "  Superhost percentage: 23.2%\n",
            "  Average review score: 4.66\n",
            "  Average number of reviews: 49.9\n"
          ]
        }
      ],
      "source": [
        "# Use IQR (Interquartile Range) method to identify price outliers\n",
        "# This is a statistical method to find unusually high or low values\n",
        "# Q1 (first quartile): 25% of prices are below this value\n",
        "# .quantile(0.25) finds the 25th percentile\n",
        "Q1 = df['price_numeric'].quantile(0.25)\n",
        "\n",
        "# Q3 (third quartile): 75% of prices are below this value\n",
        "# .quantile(0.75) finds the 75th percentile\n",
        "Q3 = df['price_numeric'].quantile(0.75)\n",
        "\n",
        "# IQR = Interquartile Range = difference between Q3 and Q1\n",
        "# This measures the spread of the middle 50% of data\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "# Calculate boundaries for outliers\n",
        "# Lower bound: Q1 - 1.5*IQR (for extremely cheap listings)\n",
        "lower_bound = Q1 - 1.5 * IQR\n",
        "\n",
        "# Upper bound: Q3 + 1.5*IQR (for extremely expensive listings)\n",
        "# Values above this are considered outliers\n",
        "upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "# Filter DataFrame to only include outliers (prices above upper_bound)\n",
        "# df['price_numeric'] > upper_bound creates boolean mask\n",
        "# df[...] filters rows where condition is True\n",
        "# .copy() creates a copy (good practice to avoid modifying original data)\n",
        "outliers = df[df['price_numeric'] > upper_bound].copy()\n",
        "\n",
        "# Display basic outlier statistics\n",
        "# len(outliers) counts number of rows (outlier listings)\n",
        "print(f\"Number of price outliers (above ${upper_bound:.2f}): {len(outliers)}\")\n",
        "print(f\"\\nOutlier price statistics:\")\n",
        "# Calculate min, max, and mean prices for outliers\n",
        "# .min(), .max(), .mean() are pandas aggregation methods\n",
        "print(f\"  Min price: ${outliers['price_numeric'].min():.2f}\")\n",
        "print(f\"  Max price: ${outliers['price_numeric'].max():.2f}\")\n",
        "print(f\"  Mean price: ${outliers['price_numeric'].mean():.2f}\")\n",
        "\n",
        "# Find the most reviewed outlier listings\n",
        "# .nlargest(5, 'number_of_reviews') gets 5 rows with highest review counts\n",
        "# [['id', 'name', ...]] selects specific columns to display\n",
        "# This creates a smaller DataFrame with just the columns we want\n",
        "most_reviewed_outliers = outliers.nlargest(5, 'number_of_reviews')[['id', 'name', 'price_numeric', 'number_of_reviews', 'amenities_count', 'host_is_superhost', 'review_scores_rating']]\n",
        "print(f\"\\nTop 5 most reviewed outliers:\")\n",
        "# .to_string() formats the DataFrame as a readable table\n",
        "print(most_reviewed_outliers.to_string())\n",
        "\n",
        "# Compare amenities between outliers and all listings\n",
        "# Calculate average amenities for outliers\n",
        "avg_amenities_outliers = outliers['amenities_count'].mean()\n",
        "\n",
        "# Calculate average amenities for all listings\n",
        "avg_amenities_all = df['amenities_count'].mean()\n",
        "\n",
        "# Display comparison\n",
        "print(f\"\\nAverage amenities:\")\n",
        "print(f\"  Outliers: {avg_amenities_outliers:.2f}\")\n",
        "print(f\"  All listings: {avg_amenities_all:.2f}\")\n",
        "print(f\"  Difference: {avg_amenities_outliers - avg_amenities_all:.2f}\")\n",
        "\n",
        "# Calculate additional insights about outliers\n",
        "print(f\"\\nOther insights about outliers:\")\n",
        "# Calculate percentage of outliers that are superhosts\n",
        "# (outliers['host_is_superhost'] == 't').sum() counts superhosts\n",
        "# len(outliers) is total number of outliers\n",
        "# * 100 converts to percentage\n",
        "# :.1f formats to 1 decimal place\n",
        "print(f\"  Superhost percentage: {(outliers['host_is_superhost'] == 't').sum() / len(outliers) * 100:.1f}%\")\n",
        "\n",
        "# Calculate average review score for outliers\n",
        "print(f\"  Average review score: {outliers['review_scores_rating'].mean():.2f}\")\n",
        "\n",
        "# Calculate average number of reviews for outliers\n",
        "print(f\"  Average number of reviews: {outliers['number_of_reviews'].mean():.1f}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
